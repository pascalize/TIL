
random cut forest: 多次元データの外れ値検出
例(?): ラベルなし時系列データから異常を検出
完全マネージドのアルゴリズム


協調フィルタリング
誰に何を勧めるかを目的としたレコメンデーション手法
新規獲得よりも既存顧客のアップセル/クロスセルに適している
見込み客獲得には、k-means等のクラスタリングで特徴を把握し、SNSユーザーを特定するなど・・・


Data Wlangler
前処理や可視化には便利
学習などには不向き

pipeモード
事前コピーせずにS3から直接ストリーミング

ファインチューニングでの「モデルの重みを初期化する」
└─ 単に、事前学習済みモデルの重みを反映すること
※ 一般的な重みの初期化とは異なる

ファインチューニングは
重みの初期化（読み込み） + 全結合層の入れ替え

XGBoost
・subsample
小さいほど木の多様性が増し、過学習を防止
≒ LLM の Temperature みたいなもの (増やすと多様化)
≒ PTv3 の mix_prob みたいなもの (増やすと多様化)
・min_child_weight
子ノードへの分割に必要なデータの最小の重みのようなもの
ノードをこれ以上分割しても有益な情報が得られないと判断する閾値
小さいと、分割に必要な制約が弱くなる。分割されやすい。
下げると分割されやすくなり、モデルが複雑化

学習率の調整による過学習の防止は、
他のことを色々検討した上で微調整としてやる程度

SageMaker Autopilot 
特徴量エンジニアリングからハイパラ探索まで自動で並列実行

HPO: 自動モデルチューニング？

シャノン情報量
ある出来事が起こる「不確かさ」や「稀少さ」を測る尺度
MLPでは、頻出だが意味情報の薄い語を削除することで、
過学習を防止可能

ベイズ最適化(Bayesian Optimization) 
https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/automatic-model-tuning-warm-start.html

エルボー法
k-means法などのクラスタリング手法において、最適なクラスタ数を決定する手法

SageMaker Debugger 
「学習中に」演算グラフを調べ、重要度の低いフィルタを除去できる

キャリブレーション（Calibration）
測定機器が正確な値を示すように、
基準となる標準器と比較して機器のズレを調整する作業

ブートストラップ
母集団の推定

F値: 特定閾値の最適化指標
AUC: 閾値に非依存

EMR
マスター、コア、タスク
タスクはスポットインスタンスでも良し
データ損失やクラスター停止には直結しない

EI (Elastic Interface)
CPUインスタンスに追加する推論専用ハードウェア

センチメント検出: 感情分析

Athena: 分析
Aurora: 格納

BlazingText: 作業負荷多め。初心者には不向き

Comprehend 
カスタム分類：単一クラス / マルチラベル

Comprehend Custom Classification
ラベル付きテキストをcsvで用意するだけで、
フルマネージドのテキスト分類モデルを自動作成できるサービス

LDA
トピック検出

Kinesis Video Stream: ストリーミング動画分析・再生
カメラ台数が増えてもストリームを水平に追加するだけで済む

Lex
カスタムスロットタイプ: 列列挙ごとに複数の同義語を登録できる

personalize の event tracker
有効化するとストリーミングイベントを取り込める
リアルタイムパーソナライゼーション機能が働き、数分内に重み付けが更新される



